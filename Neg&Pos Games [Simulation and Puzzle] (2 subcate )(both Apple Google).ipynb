{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # the stopwords \n",
    "def remain_english(line):\n",
    "    rule =re.compile(\"[^a-z^A-Z]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) # remain problems\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(str(text)) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "#             result.append(lemmatize_stemming(token))\n",
    "            result.append(remain_english(lemmatize_stemming((token))).lower()) # take out not english and return into verb, and lower it \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into pandas\n",
    "import pandas as pd\n",
    "\n",
    "fileGP = r'C:\\Users\\86137\\Desktop\\reviews\\Google Play\\Reviews\\GamesReview.csv'\n",
    "fileApple = r'C:\\Users\\86137\\Desktop\\reviews\\Apple\\Reviews\\apple-games-reviews.csv'\n",
    "\n",
    "df1 = pd.read_csv(fileGP)\n",
    "df2 = pd.read_csv(fileApple)\n",
    "# take the target subcate reviews (Apple and GP)\n",
    "\n",
    "dfSimulationGP = df1[df1.appSubGener.str.contains('Simulation')] # the Simulation games from GP\n",
    "dfPuzzleGP = df1[df1.appSubGener.str.contains('Puzzle')] # the Puzzle games from GP\n",
    "dfSimulationAp = df2[df2.genres.str.contains('Simulation')] # the Simulation games from Apple \n",
    "dfPuzzleAp = df2[df2.genres.str.contains('Puzzle')] # the Puzzle games from Apple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 18591 263994\n",
      "number of reviews text: 282585\n",
      "number of neg: 63477\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 404\n",
      "number of pos: 184938\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 433\n"
     ]
    }
   ],
   "source": [
    "# analyse Simulation part\n",
    "df1 = dfSimulationGP\n",
    "df2 = dfSimulationAp\n",
    "gpNum = dfSimulationGP.count()['text']\n",
    "ApNum = dfSimulationAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 63477\n",
      "Fitting Time: 4129.480318784714\n",
      "Topic: 0 \n",
      "Words: 0.039*\"game\" + 0.039*\"watch\" + 0.027*\"diamond\" + 0.023*\"time\" + 0.023*\"stori\" + 0.022*\"play\" + 0.021*\"energi\" + 0.019*\"gem\" + 0.018*\"wait\" + 0.016*\"want\"\n",
      "Topic: 1 \n",
      "Words: 0.128*\"game\" + 0.061*\"play\" + 0.051*\"time\" + 0.040*\"crash\" + 0.023*\"load\" + 0.018*\"start\" + 0.018*\"screen\" + 0.017*\"open\" + 0.014*\"delet\" + 0.013*\"tri\"\n",
      "Topic: 2 \n",
      "Words: 0.025*\"ball\" + 0.021*\"shoot\" + 0.020*\"time\" + 0.019*\"control\" + 0.010*\"plane\" + 0.010*\"go\" + 0.009*\"oppon\" + 0.009*\"lose\" + 0.009*\"right\" + 0.008*\"plan\"\n",
      "Topic: 3 \n",
      "Words: 0.107*\"game\" + 0.051*\"like\" + 0.020*\"bore\" + 0.019*\"look\" + 0.018*\"good\" + 0.018*\"hate\" + 0.016*\"stupid\" + 0.015*\"thing\" + 0.014*\"graphic\" + 0.014*\"play\"\n",
      "Topic: 4 \n",
      "Words: 0.085*\"game\" + 0.022*\"player\" + 0.020*\"play\" + 0.012*\"team\" + 0.010*\"develop\" + 0.009*\"gameplay\" + 0.007*\"great\" + 0.007*\"good\" + 0.006*\"better\" + 0.006*\"\"\n",
      "Topic: 5 \n",
      "Words: 0.051*\"updat\" + 0.048*\"work\" + 0.029*\"version\" + 0.025*\"connect\" + 0.024*\"iphon\" + 0.022*\"say\" + 0.020*\"phone\" + 0.019*\"ipad\" + 0.016*\"download\" + 0.015*\"devic\"\n",
      "Topic: 6 \n",
      "Words: 0.080*\"game\" + 0.056*\"money\" + 0.038*\"spend\" + 0.033*\"level\" + 0.032*\"play\" + 0.019*\"time\" + 0.014*\"coin\" + 0.012*\"real\" + 0.010*\"want\" + 0.009*\"purchas\"\n",
      "Topic: 7 \n",
      "Words: 0.091*\"game\" + 0.041*\"play\" + 0.029*\"star\" + 0.024*\"like\" + 0.024*\"updat\" + 0.023*\"review\" + 0.019*\"go\" + 0.018*\"peopl\" + 0.017*\"love\" + 0.016*\"want\"\n",
      "Topic: 8 \n",
      "Words: 0.021*\"build\" + 0.018*\"time\" + 0.018*\"item\" + 0.018*\"need\" + 0.014*\"game\" + 0.014*\"take\" + 0.013*\"thing\" + 0.011*\"quest\" + 0.010*\"complet\" + 0.010*\"event\"\n",
      "Topic: 9 \n",
      "Words: 0.032*\"support\" + 0.025*\"custom\" + 0.024*\"purchas\" + 0.020*\"game\" + 0.019*\"issu\" + 0.015*\"account\" + 0.014*\"send\" + 0.014*\"respons\" + 0.013*\"contact\" + 0.013*\"email\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 184938\n",
      "Fitting Time: 9816.025436639786\n",
      "Topic: 0 \n",
      "Words: 0.198*\"game\" + 0.082*\"love\" + 0.053*\"like\" + 0.044*\"play\" + 0.029*\"awesom\" + 0.023*\"think\" + 0.022*\"best\" + 0.018*\"amaz\" + 0.016*\"addict\" + 0.015*\"cool\"\n",
      "Topic: 1 \n",
      "Words: 0.042*\"version\" + 0.027*\"like\" + 0.024*\"car\" + 0.023*\"monster\" + 0.023*\"tabl\" + 0.021*\"ball\" + 0.019*\"drive\" + 0.018*\"pinbal\" + 0.014*\"truck\" + 0.013*\"race\"\n",
      "Topic: 2 \n",
      "Words: 0.058*\"game\" + 0.040*\"money\" + 0.033*\"level\" + 0.024*\"spend\" + 0.021*\"like\" + 0.019*\"time\" + 0.018*\"coin\" + 0.017*\"thing\" + 0.015*\"need\" + 0.015*\"play\"\n",
      "Topic: 3 \n",
      "Words: 0.019*\"button\" + 0.015*\"turn\" + 0.014*\"say\" + 0.014*\"glitch\" + 0.014*\"fix\" + 0.014*\"need\" + 0.013*\"know\" + 0.012*\"screen\" + 0.011*\"peopl\" + 0.011*\"connect\"\n",
      "Topic: 4 \n",
      "Words: 0.038*\"like\" + 0.020*\"plan\" + 0.017*\"simul\" + 0.016*\"real\" + 0.013*\"realist\" + 0.012*\"control\" + 0.011*\"hors\" + 0.011*\"flight\" + 0.011*\"train\" + 0.010*\"land\"\n",
      "Topic: 5 \n",
      "Words: 0.042*\"player\" + 0.026*\"like\" + 0.021*\"prize\" + 0.019*\"team\" + 0.016*\"weapon\" + 0.016*\"battl\" + 0.013*\"hunt\" + 0.013*\"shoot\" + 0.013*\"mode\" + 0.013*\"kill\"\n",
      "Topic: 6 \n",
      "Words: 0.085*\"game\" + 0.060*\"play\" + 0.038*\"updat\" + 0.030*\"love\" + 0.028*\"time\" + 0.017*\"crash\" + 0.016*\"start\" + 0.014*\"go\" + 0.014*\"stori\" + 0.014*\"stop\"\n",
      "Topic: 7 \n",
      "Words: 0.040*\"like\" + 0.022*\"thing\" + 0.018*\"love\" + 0.018*\"anim\" + 0.015*\"abl\" + 0.014*\"think\" + 0.013*\"need\" + 0.012*\"peopl\" + 0.012*\"dragon\" + 0.011*\"want\"\n",
      "Topic: 8 \n",
      "Words: 0.081*\"game\" + 0.034*\"play\" + 0.020*\"time\" + 0.017*\"enjoy\" + 0.015*\"challeng\" + 0.011*\"level\" + 0.008*\"make\" + 0.007*\"develop\" + 0.007*\"great\" + 0.007*\"easi\"\n",
      "Topic: 9 \n",
      "Words: 0.155*\"game\" + 0.078*\"good\" + 0.076*\"great\" + 0.037*\"graphic\" + 0.034*\"time\" + 0.025*\"play\" + 0.018*\"work\" + 0.018*\"nice\" + 0.017*\"better\" + 0.016*\"easi\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Puzzle Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 6504 263363\n",
      "number of reviews text: 269867\n",
      "number of neg: 43178\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 241\n",
      "number of pos: 199926\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 376\n"
     ]
    }
   ],
   "source": [
    "# analyse Arcade part\n",
    "df1 = dfPuzzleGP\n",
    "df2 = dfPuzzleAp\n",
    "\n",
    "gpNum = dfPuzzleGP.count()['text']\n",
    "ApNum = dfPuzzleAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 43178\n",
      "Fitting Time: 1778.4108712673187\n",
      "Topic: 0 \n",
      "Words: 0.086*\"game\" + 0.047*\"money\" + 0.020*\"pay\" + 0.017*\"purchas\" + 0.017*\"play\" + 0.014*\"spend\" + 0.014*\"free\" + 0.014*\"want\" + 0.013*\"develop\" + 0.013*\"peopl\"\n",
      "Topic: 1 \n",
      "Words: 0.079*\"level\" + 0.068*\"game\" + 0.036*\"play\" + 0.022*\"time\" + 0.017*\"spend\" + 0.017*\"money\" + 0.012*\"like\" + 0.012*\"need\" + 0.010*\"live\" + 0.010*\"complet\"\n",
      "Topic: 2 \n",
      "Words: 0.085*\"coin\" + 0.031*\"daili\" + 0.027*\"earn\" + 0.025*\"purchas\" + 0.024*\"card\" + 0.023*\"\" + 0.021*\"reward\" + 0.019*\"gold\" + 0.019*\"free\" + 0.017*\"prize\"\n",
      "Topic: 3 \n",
      "Words: 0.093*\"game\" + 0.051*\"updat\" + 0.045*\"play\" + 0.031*\"time\" + 0.028*\"crash\" + 0.022*\"work\" + 0.018*\"freez\" + 0.017*\"open\" + 0.017*\"screen\" + 0.017*\"love\"\n",
      "Topic: 4 \n",
      "Words: 0.136*\"version\" + 0.045*\"upgrad\" + 0.021*\"free\" + 0.020*\"charact\" + 0.014*\"dont\" + 0.013*\"stone\" + 0.012*\"lame\" + 0.011*\"pay\" + 0.011*\"hate\" + 0.011*\"better\"\n",
      "Topic: 5 \n",
      "Words: 0.025*\"game\" + 0.022*\"support\" + 0.022*\"facebook\" + 0.021*\"connect\" + 0.020*\"play\" + 0.018*\"friend\" + 0.018*\"say\" + 0.017*\"issu\" + 0.015*\"send\" + 0.013*\"help\"\n",
      "Topic: 6 \n",
      "Words: 0.088*\"puzzl\" + 0.023*\"sound\" + 0.019*\"scan\" + 0.019*\"like\" + 0.017*\"music\" + 0.015*\"kid\" + 0.015*\"turn\" + 0.014*\"solv\" + 0.013*\"work\" + 0.012*\"tri\"\n",
      "Topic: 7 \n",
      "Words: 0.129*\"game\" + 0.062*\"play\" + 0.033*\"time\" + 0.024*\"second\" + 0.024*\"watch\" + 0.019*\"level\" + 0.018*\"delet\" + 0.017*\"like\" + 0.017*\"want\" + 0.016*\"annoy\"\n",
      "Topic: 8 \n",
      "Words: 0.087*\"game\" + 0.025*\"like\" + 0.014*\"play\" + 0.013*\"star\" + 0.011*\"good\" + 0.010*\"think\" + 0.009*\"chang\" + 0.009*\"better\" + 0.009*\"piec\" + 0.008*\"look\"\n",
      "Topic: 9 \n",
      "Words: 0.069*\"word\" + 0.017*\"letter\" + 0.016*\"screen\" + 0.016*\"button\" + 0.015*\"color\" + 0.014*\"pictur\" + 0.013*\"number\" + 0.012*\"time\" + 0.012*\"hint\" + 0.012*\"answer\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 199926\n",
      "Fitting Time: 5475.417810916901\n",
      "Topic: 0 \n",
      "Words: 0.058*\"free\" + 0.054*\"game\" + 0.038*\"version\" + 0.029*\"review\" + 0.023*\"worth\" + 0.021*\"like\" + 0.019*\"peopl\" + 0.017*\"purchas\" + 0.016*\"download\" + 0.015*\"think\"\n",
      "Topic: 1 \n",
      "Words: 0.158*\"level\" + 0.059*\"game\" + 0.028*\"challeng\" + 0.026*\"play\" + 0.020*\"hard\" + 0.019*\"beat\" + 0.019*\"like\" + 0.015*\"easi\" + 0.015*\"get\" + 0.012*\"score\"\n",
      "Topic: 2 \n",
      "Words: 0.122*\"game\" + 0.080*\"like\" + 0.039*\"love\" + 0.028*\"awesom\" + 0.022*\"better\" + 0.020*\"cool\" + 0.019*\"thing\" + 0.018*\"think\" + 0.016*\"cute\" + 0.013*\"good\"\n",
      "Topic: 3 \n",
      "Words: 0.108*\"game\" + 0.055*\"challeng\" + 0.048*\"great\" + 0.045*\"think\" + 0.037*\"word\" + 0.037*\"good\" + 0.028*\"love\" + 0.024*\"make\" + 0.023*\"puzzl\" + 0.023*\"easi\"\n",
      "Topic: 4 \n",
      "Words: 0.085*\"game\" + 0.025*\"puzzl\" + 0.022*\"graphic\" + 0.018*\"great\" + 0.016*\"music\" + 0.012*\"simpl\" + 0.011*\"stori\" + 0.011*\"design\" + 0.010*\"sound\" + 0.010*\"look\"\n",
      "Topic: 5 \n",
      "Words: 0.057*\"puzzl\" + 0.033*\"like\" + 0.025*\"color\" + 0.020*\"love\" + 0.016*\"piec\" + 0.015*\"number\" + 0.015*\"option\" + 0.014*\"pictur\" + 0.011*\"differ\" + 0.010*\"thing\"\n",
      "Topic: 6 \n",
      "Words: 0.195*\"game\" + 0.162*\"play\" + 0.111*\"love\" + 0.063*\"addict\" + 0.024*\"stop\" + 0.021*\"year\" + 0.019*\"best\" + 0.016*\"recommend\" + 0.015*\"download\" + 0.015*\"start\"\n",
      "Topic: 7 \n",
      "Words: 0.077*\"game\" + 0.075*\"play\" + 0.065*\"time\" + 0.040*\"wait\" + 0.032*\"spend\" + 0.029*\"long\" + 0.026*\"like\" + 0.023*\"money\" + 0.022*\"hour\" + 0.020*\"take\"\n",
      "Topic: 8 \n",
      "Words: 0.043*\"star\" + 0.040*\"coin\" + 0.027*\"earn\" + 0.022*\"need\" + 0.017*\"power\" + 0.016*\"give\" + 0.016*\"item\" + 0.015*\"daili\" + 0.015*\"extra\" + 0.014*\"reward\"\n",
      "Topic: 9 \n",
      "Words: 0.068*\"game\" + 0.048*\"time\" + 0.046*\"updat\" + 0.021*\"pass\" + 0.021*\"problem\" + 0.019*\"work\" + 0.019*\"play\" + 0.017*\"great\" + 0.014*\"crash\" + 0.013*\"love\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
