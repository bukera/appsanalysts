{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # the stopwords \n",
    "def remain_english(line):\n",
    "    rule =re.compile(\"[^a-z^A-Z]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) # remain problems\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(str(text)) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "#             result.append(lemmatize_stemming(token))\n",
    "            result.append(remain_english(lemmatize_stemming((token))).lower()) # take out not english and return into verb, and lower it \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into pandas\n",
    "import pandas as pd\n",
    "fileGP = r'C:\\Users\\Administrator\\Desktop\\reviewData\\Reviews(GP)\\EducationReview.csv'\n",
    "fileApple = r'C:\\Users\\Administrator\\Desktop\\reviewData\\Reviews(Ap)\\apple-education-reviews.csv'\n",
    "# file = r'C:\\Users\\Administrator\\Desktop\\reviewData\\dist\\lifestyle-dist.csv'\n",
    "df1 = pd.read_csv(fileGP)\n",
    "df2 = pd.read_csv(fileApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews text: 219999\n",
      "number of neg: 36006\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 350\n",
      "number of pos: 169155\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 208\n"
     ]
    }
   ],
   "source": [
    "gpNum = df1.count()['text']\n",
    "ApNum = df2.count()['text'] # text(reviews) number from apple\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "# text_num = 5500\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in range(gpNum):\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in range(ApNum):\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 36006\n",
      "Fitting Time: 2518.8920724391937\n",
      "Topic: 0 \n",
      "Words: 0.044*\"work\" + 0.042*\"updat\" + 0.038*\"time\" + 0.034*\"crash\" + 0.027*\"open\" + 0.018*\"tri\" + 0.017*\"load\" + 0.016*\"download\" + 0.014*\"screen\" + 0.011*\"delet\"\n",
      "Topic: 1 \n",
      "Words: 0.177*\"\" + 0.128*\"version\" + 0.063*\"purchas\" + 0.061*\"sound\" + 0.040*\"upgrad\" + 0.028*\"letter\" + 0.021*\"buy\" + 0.015*\"code\" + 0.014*\"pay\" + 0.011*\"restor\"\n",
      "Topic: 2 \n",
      "Words: 0.075*\"game\" + 0.035*\"free\" + 0.033*\"money\" + 0.031*\"play\" + 0.031*\"like\" + 0.023*\"want\" + 0.022*\"wast\" + 0.018*\"time\" + 0.017*\"think\" + 0.014*\"download\"\n",
      "Topic: 3 \n",
      "Words: 0.034*\"month\" + 0.026*\"subscript\" + 0.021*\"pay\" + 0.021*\"free\" + 0.020*\"charg\" + 0.017*\"email\" + 0.016*\"account\" + 0.015*\"purchas\" + 0.015*\"cancel\" + 0.014*\"year\"\n",
      "Topic: 4 \n",
      "Words: 0.029*\"grade\" + 0.017*\"class\" + 0.016*\"book\" + 0.015*\"student\" + 0.014*\"need\" + 0.014*\"school\" + 0.012*\"like\" + 0.011*\"read\" + 0.010*\"better\" + 0.010*\"card\"\n",
      "Topic: 5 \n",
      "Words: 0.041*\"question\" + 0.036*\"answer\" + 0.032*\"test\" + 0.024*\"time\" + 0.021*\"wrong\" + 0.020*\"button\" + 0.014*\"problem\" + 0.014*\"take\" + 0.013*\"correct\" + 0.013*\"say\"\n",
      "Topic: 6 \n",
      "Words: 0.044*\"play\" + 0.028*\"song\" + 0.027*\"note\" + 0.018*\"highlight\" + 0.018*\"listen\" + 0.015*\"piano\" + 0.014*\"tree\" + 0.014*\"background\" + 0.013*\"music\" + 0.013*\"voic\"\n",
      "Topic: 7 \n",
      "Words: 0.107*\"work\" + 0.062*\"video\" + 0.057*\"ipad\" + 0.043*\"cours\" + 0.039*\"download\" + 0.034*\"iphon\" + 0.029*\"watch\" + 0.021*\"content\" + 0.014*\"view\" + 0.014*\"devic\"\n",
      "Topic: 8 \n",
      "Words: 0.028*\"star\" + 0.025*\"kid\" + 0.021*\"like\" + 0.017*\"pictur\" + 0.016*\"love\" + 0.015*\"plant\" + 0.014*\"toca\" + 0.012*\"thing\" + 0.011*\"hate\" + 0.011*\"children\"\n",
      "Topic: 9 \n",
      "Words: 0.034*\"learn\" + 0.024*\"word\" + 0.018*\"lesson\" + 0.012*\"languag\" + 0.012*\"good\" + 0.012*\"like\" + 0.009*\"review\" + 0.009*\"teach\" + 0.009*\"know\" + 0.008*\"great\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=2)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 169155\n",
      "Fitting Time: 8587.309166193008\n",
      "Topic: 0 \n",
      "Words: 0.067*\"help\" + 0.037*\"math\" + 0.036*\"school\" + 0.033*\"grade\" + 0.032*\"student\" + 0.026*\"class\" + 0.025*\"love\" + 0.021*\"teacher\" + 0.019*\"great\" + 0.019*\"work\"\n",
      "Topic: 1 \n",
      "Words: 0.023*\"like\" + 0.023*\"updat\" + 0.018*\"work\" + 0.016*\"star\" + 0.013*\"abl\" + 0.013*\"option\" + 0.013*\"time\" + 0.012*\"featur\" + 0.011*\"need\" + 0.011*\"thing\"\n",
      "Topic: 2 \n",
      "Words: 0.138*\"good\" + 0.054*\"best\" + 0.048*\"free\" + 0.024*\"pretti\" + 0.024*\"app\" + 0.024*\"like\" + 0.016*\"better\" + 0.014*\"version\" + 0.013*\"think\" + 0.012*\"graph\"\n",
      "Topic: 3 \n",
      "Words: 0.111*\"game\" + 0.053*\"play\" + 0.053*\"love\" + 0.046*\"like\" + 0.021*\"think\" + 0.021*\"toca\" + 0.014*\"littl\" + 0.013*\"thing\" + 0.012*\"color\" + 0.011*\"want\"\n",
      "Topic: 4 \n",
      "Words: 0.103*\"love\" + 0.055*\"year\" + 0.037*\"kid\" + 0.024*\"daughter\" + 0.023*\"teach\" + 0.022*\"great\" + 0.021*\"learn\" + 0.019*\"worth\" + 0.018*\"read\" + 0.018*\"educ\"\n",
      "Topic: 5 \n",
      "Words: 0.079*\"great\" + 0.034*\"learn\" + 0.023*\"cours\" + 0.020*\"video\" + 0.019*\"lesson\" + 0.019*\"japanes\" + 0.018*\"level\" + 0.014*\"work\" + 0.014*\"tool\" + 0.013*\"song\"\n",
      "Topic: 6 \n",
      "Words: 0.177*\"\" + 0.136*\"nice\" + 0.042*\"cool\" + 0.018*\"countri\" + 0.014*\"chines\" + 0.013*\"monkey\" + 0.011*\"nasa\" + 0.011*\"geographi\" + 0.009*\"kitchen\" + 0.009*\"icon\"\n",
      "Topic: 7 \n",
      "Words: 0.057*\"easi\" + 0.027*\"thank\" + 0.024*\"use\" + 0.021*\"great\" + 0.019*\"iphon\" + 0.018*\"inform\" + 0.017*\"excel\" + 0.017*\"simpl\" + 0.016*\"applic\" + 0.014*\"make\"\n",
      "Topic: 8 \n",
      "Words: 0.091*\"learn\" + 0.043*\"word\" + 0.031*\"languag\" + 0.028*\"help\" + 0.019*\"like\" + 0.016*\"spanish\" + 0.013*\"card\" + 0.013*\"great\" + 0.013*\"easi\" + 0.012*\"want\"\n",
      "Topic: 9 \n",
      "Words: 0.049*\"studi\" + 0.041*\"test\" + 0.033*\"question\" + 0.029*\"time\" + 0.027*\"help\" + 0.021*\"answer\" + 0.015*\"take\" + 0.014*\"review\" + 0.014*\"great\" + 0.012*\"write\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=2)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try anlanyse with tfidf(Pos)\n",
    "tfidf = models.TfidfModel(doc_term_matrix)\n",
    "corpus_tfidf = tfidf[doc_term_matrix]\n",
    "start = time.time()\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=100, workers=2)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try anlanyse with tfidf(Neg)\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "tfidf = models.TfidfModel(doc_term_matrix)\n",
    "corpus_tfidf = tfidf[doc_term_matrix]\n",
    "start = time.time()\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=100, workers=2)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
