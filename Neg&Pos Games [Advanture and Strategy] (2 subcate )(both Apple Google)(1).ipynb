{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B_Areej\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\B_Areej\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # the stopwords \n",
    "def remain_english(line):\n",
    "    rule =re.compile(\"[^a-z^A-Z]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) # remain problems\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(str(text)) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "#             result.append(lemmatize_stemming(token))\n",
    "            result.append(remain_english(lemmatize_stemming((token))).lower()) # take out not english and return into verb, and lower it \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into pandas\n",
    "import pandas as pd\n",
    "\n",
    "fileGP = r'GamesReview.csv'\n",
    "fileApple = r'apple-games-reviews.csv'\n",
    "\n",
    "df1 = pd.read_csv(fileGP)\n",
    "df2 = pd.read_csv(fileApple)\n",
    "# take the target subcate reviews (Apple and GP)\n",
    "dfAdventureGP = df1[df1.appSubGener.str.contains('Adventure')] # the Adventure games from GP\n",
    "dfStrategyGP = df1[df1.appSubGener.str.contains('Strategy')] # the Strategy games from GP\n",
    "\n",
    "dfAdventureAp = df2[df2.genres.str.contains('Adventure')] # the Adventure games from Apple \n",
    "dfStrategyAp = df2[df2.genres.str.contains('Strategy')] # the Strategy games from Apple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\B_Areej\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adventure part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 7862 208041\n",
      "number of reviews text: 215903\n",
      "number of neg: 41834\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 200\n",
      "number of pos: 149281\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 366\n"
     ]
    }
   ],
   "source": [
    "# analyse Adventure part\n",
    "df1 = dfAdventureGP\n",
    "df2 = dfAdventureAp\n",
    "gpNum = dfAdventureGP.count()['text']\n",
    "ApNum = dfAdventureAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 41834\n",
      "Fitting Time: 1126.0647239685059\n",
      "Topic: 0 \n",
      "Words: 0.035*\"control\" + 0.034*\"game\" + 0.021*\"kill\" + 0.013*\"like\" + 0.013*\"shoot\" + 0.013*\"jump\" + 0.011*\"button\" + 0.011*\"hard\" + 0.011*\"time\" + 0.010*\"zombi\"\n",
      "Topic: 1 \n",
      "Words: 0.047*\"game\" + 0.036*\"play\" + 0.034*\"energi\" + 0.029*\"time\" + 0.018*\"wait\" + 0.018*\"item\" + 0.017*\"take\" + 0.017*\"need\" + 0.015*\"like\" + 0.015*\"quest\"\n",
      "Topic: 2 \n",
      "Words: 0.075*\"game\" + 0.025*\"like\" + 0.013*\"stori\" + 0.012*\"review\" + 0.012*\"star\" + 0.011*\"good\" + 0.011*\"play\" + 0.010*\"look\" + 0.010*\"charact\" + 0.009*\"think\"\n",
      "Topic: 3 \n",
      "Words: 0.076*\"game\" + 0.037*\"play\" + 0.036*\"peopl\" + 0.023*\"like\" + 0.022*\"world\" + 0.018*\"think\" + 0.017*\"know\" + 0.017*\"want\" + 0.014*\"friend\" + 0.012*\"say\"\n",
      "Topic: 4 \n",
      "Words: 0.127*\"game\" + 0.029*\"stupid\" + 0.029*\"play\" + 0.029*\"like\" + 0.028*\"time\" + 0.027*\"wast\" + 0.025*\"hate\" + 0.021*\"download\" + 0.016*\"minecraft\" + 0.016*\"worst\"\n",
      "Topic: 5 \n",
      "Words: 0.142*\"level\" + 0.022*\"battl\" + 0.019*\"beat\" + 0.015*\"monster\" + 0.015*\"dragon\" + 0.013*\"food\" + 0.011*\"match\" + 0.010*\"get\" + 0.008*\"breed\" + 0.008*\"boss\"\n",
      "Topic: 6 \n",
      "Words: 0.082*\"game\" + 0.056*\"money\" + 0.036*\"spend\" + 0.024*\"play\" + 0.017*\"time\" + 0.016*\"purchas\" + 0.012*\"want\" + 0.012*\"gem\" + 0.011*\"real\" + 0.010*\"coin\"\n",
      "Topic: 7 \n",
      "Words: 0.109*\"game\" + 0.054*\"play\" + 0.032*\"crash\" + 0.029*\"time\" + 0.021*\"updat\" + 0.018*\"screen\" + 0.017*\"load\" + 0.017*\"start\" + 0.015*\"open\" + 0.014*\"work\"\n",
      "Topic: 8 \n",
      "Words: 0.041*\"work\" + 0.024*\"time\" + 0.024*\"custom\" + 0.021*\"connect\" + 0.020*\"support\" + 0.020*\"say\" + 0.016*\"tri\" + 0.016*\"account\" + 0.014*\"help\" + 0.012*\"issu\"\n",
      "Topic: 9 \n",
      "Words: 0.052*\"game\" + 0.041*\"updat\" + 0.030*\"player\" + 0.013*\"year\" + 0.012*\"develop\" + 0.012*\"play\" + 0.012*\"chang\" + 0.010*\"star\" + 0.010*\"month\" + 0.009*\"peopl\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 149281\n",
      "Fitting Time: 4577.42399430275\n",
      "Topic: 0 \n",
      "Words: 0.101*\"game\" + 0.095*\"level\" + 0.044*\"good\" + 0.033*\"time\" + 0.026*\"challeng\" + 0.026*\"hard\" + 0.022*\"easi\" + 0.019*\"pretti\" + 0.019*\"play\" + 0.018*\"great\"\n",
      "Topic: 1 \n",
      "Words: 0.047*\"game\" + 0.041*\"peopl\" + 0.029*\"like\" + 0.018*\"friend\" + 0.016*\"thing\" + 0.016*\"play\" + 0.016*\"player\" + 0.015*\"think\" + 0.015*\"know\" + 0.014*\"good\"\n",
      "Topic: 2 \n",
      "Words: 0.087*\"game\" + 0.023*\"stori\" + 0.019*\"great\" + 0.018*\"graphic\" + 0.018*\"play\" + 0.012*\"gameplay\" + 0.010*\"charact\" + 0.009*\"amaz\" + 0.009*\"control\" + 0.009*\"worth\"\n",
      "Topic: 3 \n",
      "Words: 0.061*\"game\" + 0.039*\"money\" + 0.025*\"time\" + 0.024*\"play\" + 0.024*\"spend\" + 0.020*\"like\" + 0.020*\"energi\" + 0.017*\"thing\" + 0.015*\"need\" + 0.014*\"coin\"\n",
      "Topic: 4 \n",
      "Words: 0.055*\"like\" + 0.044*\"love\" + 0.030*\"game\" + 0.018*\"anim\" + 0.017*\"think\" + 0.016*\"thing\" + 0.014*\"cute\" + 0.012*\"charact\" + 0.011*\"hors\" + 0.011*\"dragon\"\n",
      "Topic: 5 \n",
      "Words: 0.046*\"game\" + 0.036*\"like\" + 0.020*\"weapon\" + 0.020*\"control\" + 0.019*\"great\" + 0.017*\"better\" + 0.016*\"need\" + 0.016*\"kill\" + 0.014*\"zombi\" + 0.014*\"shoot\"\n",
      "Topic: 6 \n",
      "Words: 0.025*\"episod\" + 0.025*\"room\" + 0.018*\"puzzl\" + 0.016*\"object\" + 0.011*\"look\" + 0.011*\"hide\" + 0.011*\"know\" + 0.010*\"chapter\" + 0.010*\"season\" + 0.010*\"figur\"\n",
      "Topic: 7 \n",
      "Words: 0.214*\"game\" + 0.088*\"play\" + 0.079*\"love\" + 0.027*\"great\" + 0.026*\"like\" + 0.025*\"best\" + 0.024*\"awesom\" + 0.019*\"addict\" + 0.018*\"amaz\" + 0.015*\"recommend\"\n",
      "Topic: 8 \n",
      "Words: 0.084*\"game\" + 0.038*\"updat\" + 0.037*\"play\" + 0.023*\"time\" + 0.019*\"crash\" + 0.019*\"problem\" + 0.019*\"love\" + 0.017*\"work\" + 0.013*\"glitch\" + 0.011*\"start\"\n",
      "Topic: 9 \n",
      "Words: 0.023*\"build\" + 0.019*\"like\" + 0.019*\"battl\" + 0.018*\"item\" + 0.015*\"monster\" + 0.013*\"need\" + 0.011*\"fight\" + 0.011*\"charact\" + 0.011*\"island\" + 0.010*\"thing\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Strategy Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 12371 197903\n",
      "number of reviews text: 210274\n",
      "number of neg: 46501\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 237\n",
      "number of pos: 142298\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 304\n"
     ]
    }
   ],
   "source": [
    "# analyse strategy part\n",
    "df1 = dfStrategyGP\n",
    "df2 = dfStrategyAp\n",
    "gpNum = dfStrategyGP.count()['text']\n",
    "ApNum = dfStrategyAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 46501\n",
      "Fitting Time: 2095.3590557575226\n",
      "Topic: 0 \n",
      "Words: 0.040*\"game\" + 0.031*\"version\" + 0.023*\"play\" + 0.015*\"updat\" + 0.014*\"card\" + 0.011*\"screen\" + 0.010*\"button\" + 0.010*\"like\" + 0.009*\"turn\" + 0.008*\"control\"\n",
      "Topic: 1 \n",
      "Words: 0.060*\"level\" + 0.040*\"game\" + 0.017*\"attack\" + 0.017*\"player\" + 0.017*\"play\" + 0.016*\"time\" + 0.015*\"lose\" + 0.014*\"card\" + 0.011*\"match\" + 0.011*\"troop\"\n",
      "Topic: 2 \n",
      "Words: 0.043*\"game\" + 0.027*\"support\" + 0.025*\"custom\" + 0.019*\"issu\" + 0.015*\"develop\" + 0.012*\"respons\" + 0.012*\"problem\" + 0.012*\"servic\" + 0.011*\"help\" + 0.010*\"player\"\n",
      "Topic: 3 \n",
      "Words: 0.082*\"game\" + 0.022*\"like\" + 0.020*\"play\" + 0.014*\"time\" + 0.013*\"wait\" + 0.010*\"bore\" + 0.010*\"thing\" + 0.009*\"clan\" + 0.009*\"\" + 0.009*\"clash\"\n",
      "Topic: 4 \n",
      "Words: 0.047*\"roll\" + 0.023*\"time\" + 0.022*\"random\" + 0.022*\"play\" + 0.019*\"piec\" + 0.018*\"dice\" + 0.017*\"need\" + 0.017*\"doubl\" + 0.016*\"cheat\" + 0.015*\"black\"\n",
      "Topic: 5 \n",
      "Words: 0.137*\"game\" + 0.040*\"like\" + 0.031*\"play\" + 0.028*\"star\" + 0.024*\"review\" + 0.021*\"peopl\" + 0.016*\"download\" + 0.014*\"good\" + 0.014*\"think\" + 0.013*\"want\"\n",
      "Topic: 6 \n",
      "Words: 0.048*\"player\" + 0.042*\"game\" + 0.027*\"play\" + 0.016*\"peopl\" + 0.013*\"chines\" + 0.011*\"park\" + 0.010*\"world\" + 0.010*\"chat\" + 0.009*\"partner\" + 0.009*\"team\"\n",
      "Topic: 7 \n",
      "Words: 0.080*\"game\" + 0.055*\"money\" + 0.049*\"spend\" + 0.029*\"play\" + 0.019*\"time\" + 0.014*\"player\" + 0.010*\"build\" + 0.009*\"real\" + 0.009*\"level\" + 0.009*\"want\"\n",
      "Topic: 8 \n",
      "Words: 0.111*\"game\" + 0.050*\"play\" + 0.033*\"updat\" + 0.033*\"time\" + 0.029*\"crash\" + 0.017*\"work\" + 0.015*\"load\" + 0.015*\"start\" + 0.012*\"open\" + 0.011*\"screen\"\n",
      "Topic: 9 \n",
      "Words: 0.038*\"purchas\" + 0.030*\"gem\" + 0.029*\"account\" + 0.027*\"coin\" + 0.024*\"watch\" + 0.020*\"money\" + 0.019*\"buy\" + 0.017*\"game\" + 0.016*\"want\" + 0.015*\"gold\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 142298\n",
      "Fitting Time: 3527.2574694156647\n",
      "Topic: 0 \n",
      "Words: 0.091*\"level\" + 0.022*\"hard\" + 0.021*\"beat\" + 0.017*\"time\" + 0.017*\"challeng\" + 0.015*\"game\" + 0.012*\"button\" + 0.012*\"get\" + 0.011*\"need\" + 0.011*\"easi\"\n",
      "Topic: 1 \n",
      "Words: 0.110*\"game\" + 0.063*\"play\" + 0.036*\"updat\" + 0.021*\"love\" + 0.020*\"time\" + 0.015*\"great\" + 0.013*\"work\" + 0.012*\"crash\" + 0.012*\"version\" + 0.011*\"phone\"\n",
      "Topic: 2 \n",
      "Words: 0.153*\"game\" + 0.044*\"great\" + 0.042*\"play\" + 0.032*\"good\" + 0.018*\"graphic\" + 0.016*\"like\" + 0.015*\"enjoy\" + 0.013*\"easi\" + 0.012*\"strategi\" + 0.012*\"recommend\"\n",
      "Topic: 3 \n",
      "Words: 0.209*\"game\" + 0.155*\"love\" + 0.069*\"play\" + 0.055*\"addict\" + 0.043*\"awesom\" + 0.033*\"best\" + 0.017*\"amaz\" + 0.017*\"like\" + 0.014*\"\" + 0.012*\"super\"\n",
      "Topic: 4 \n",
      "Words: 0.039*\"build\" + 0.036*\"battl\" + 0.033*\"like\" + 0.032*\"attack\" + 0.025*\"base\" + 0.025*\"clan\" + 0.024*\"troop\" + 0.023*\"unit\" + 0.022*\"clash\" + 0.016*\"citi\"\n",
      "Topic: 5 \n",
      "Words: 0.043*\"player\" + 0.021*\"card\" + 0.014*\"play\" + 0.013*\"game\" + 0.013*\"peopl\" + 0.011*\"team\" + 0.010*\"allianc\" + 0.009*\"match\" + 0.009*\"help\" + 0.008*\"develop\"\n",
      "Topic: 6 \n",
      "Words: 0.039*\"tower\" + 0.033*\"star\" + 0.025*\"hero\" + 0.024*\"defens\" + 0.020*\"mode\" + 0.019*\"weapon\" + 0.018*\"map\" + 0.017*\"upgrad\" + 0.015*\"like\" + 0.014*\"updat\"\n",
      "Topic: 7 \n",
      "Words: 0.078*\"like\" + 0.071*\"game\" + 0.030*\"thing\" + 0.029*\"think\" + 0.023*\"cool\" + 0.023*\"peopl\" + 0.019*\"great\" + 0.018*\"good\" + 0.015*\"know\" + 0.014*\"want\"\n",
      "Topic: 8 \n",
      "Words: 0.094*\"game\" + 0.050*\"time\" + 0.036*\"play\" + 0.036*\"money\" + 0.029*\"spend\" + 0.020*\"like\" + 0.017*\"great\" + 0.015*\"good\" + 0.014*\"free\" + 0.014*\"upgrad\"\n",
      "Topic: 9 \n",
      "Words: 0.030*\"night\" + 0.027*\"sound\" + 0.023*\"music\" + 0.016*\"roll\" + 0.016*\"cheat\" + 0.011*\"doubl\" + 0.011*\"effect\" + 0.011*\"dice\" + 0.010*\"port\" + 0.008*\"jump\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
