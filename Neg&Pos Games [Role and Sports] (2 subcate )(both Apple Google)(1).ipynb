{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zmz22\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zmz22\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # the stopwords \n",
    "def remain_english(line):\n",
    "    rule =re.compile(\"[^a-z^A-Z]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) # remain problems\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(str(text)) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "#             result.append(lemmatize_stemming(token))\n",
    "            result.append(remain_english(lemmatize_stemming((token))).lower()) # take out not english and return into verb, and lower it \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into pandas\n",
    "import pandas as pd\n",
    "\n",
    "fileGP = r'C:\\Users\\zmz22\\Downloads\\GamesReview.csv'\n",
    "fileApple = r'C:\\Users\\zmz22\\Downloads\\apple-games-reviews.csv'\n",
    "\n",
    "df1 = pd.read_csv(fileGP)\n",
    "df2 = pd.read_csv(fileApple)\n",
    "# take the target subcate reviews (Apple and GP)\n",
    "\n",
    "dfRoleGP = df1[df1.appSubGener.str.contains('Role')] # the Role games from GP\n",
    "dfSportsGP = df1[df1.appSubGener.str.contains('Sports')] # the Sports games from GP\n",
    "dfRoleAp = df2[df2.genres.str.contains('Role')] # the Role games from Apple \n",
    "dfSportsAp = df2[df2.genres.str.contains('Sports')] # the Sports games from Apple \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=152160, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.score.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 7220 187122\n",
      "number of reviews text: 194342\n",
      "number of neg: 39965\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 189\n",
      "number of pos: 133567\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 257\n"
     ]
    }
   ],
   "source": [
    "# analyse Role part\n",
    "df1 = dfRoleGP\n",
    "df2 = dfRoleAp\n",
    "gpNum = dfRoleGP.count()['text']\n",
    "ApNum = dfRoleAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 39965\n",
      "Fitting Time: 3178.112509250641\n",
      "Topic: 0 \n",
      "Words: 0.044*\"level\" + 0.022*\"card\" + 0.022*\"game\" + 0.019*\"team\" + 0.017*\"monster\" + 0.016*\"battl\" + 0.015*\"lose\" + 0.014*\"match\" + 0.013*\"beat\" + 0.012*\"time\"\n",
      "Topic: 1 \n",
      "Words: 0.039*\"game\" + 0.034*\"support\" + 0.026*\"custom\" + 0.018*\"issu\" + 0.017*\"purchas\" + 0.015*\"money\" + 0.013*\"respons\" + 0.013*\"servic\" + 0.012*\"account\" + 0.012*\"help\"\n",
      "Topic: 2 \n",
      "Words: 0.050*\"game\" + 0.015*\"charact\" + 0.012*\"like\" + 0.012*\"quest\" + 0.010*\"gameplay\" + 0.009*\"weapon\" + 0.009*\"play\" + 0.008*\"graphic\" + 0.008*\"need\" + 0.007*\"great\"\n",
      "Topic: 3 \n",
      "Words: 0.062*\"game\" + 0.040*\"player\" + 0.023*\"spend\" + 0.022*\"play\" + 0.016*\"peopl\" + 0.016*\"attack\" + 0.015*\"money\" + 0.014*\"time\" + 0.012*\"level\" + 0.012*\"build\"\n",
      "Topic: 4 \n",
      "Words: 0.103*\"game\" + 0.036*\"like\" + 0.026*\"play\" + 0.014*\"look\" + 0.013*\"peopl\" + 0.013*\"think\" + 0.012*\"thing\" + 0.011*\"good\" + 0.011*\"want\" + 0.009*\"better\"\n",
      "Topic: 5 \n",
      "Words: 0.095*\"game\" + 0.047*\"crash\" + 0.038*\"play\" + 0.035*\"time\" + 0.026*\"load\" + 0.025*\"screen\" + 0.022*\"work\" + 0.016*\"updat\" + 0.015*\"open\" + 0.014*\"start\"\n",
      "Topic: 6 \n",
      "Words: 0.090*\"game\" + 0.063*\"money\" + 0.045*\"spend\" + 0.036*\"play\" + 0.027*\"time\" + 0.013*\"want\" + 0.012*\"real\" + 0.011*\"wast\" + 0.011*\"level\" + 0.011*\"like\"\n",
      "Topic: 7 \n",
      "Words: 0.061*\"game\" + 0.025*\"charact\" + 0.022*\"player\" + 0.015*\"event\" + 0.014*\"play\" + 0.012*\"star\" + 0.011*\"updat\" + 0.010*\"develop\" + 0.009*\"reward\" + 0.008*\"chang\"\n",
      "Topic: 8 \n",
      "Words: 0.086*\"game\" + 0.046*\"updat\" + 0.042*\"play\" + 0.020*\"say\" + 0.019*\"download\" + 0.017*\"connect\" + 0.017*\"delet\" + 0.015*\"time\" + 0.015*\"go\" + 0.014*\"lose\"\n",
      "Topic: 9 \n",
      "Words: 0.032*\"diamond\" + 0.031*\"stori\" + 0.027*\"like\" + 0.020*\"choic\" + 0.016*\"gem\" + 0.016*\"want\" + 0.012*\"thing\" + 0.012*\"cloth\" + 0.012*\"need\" + 0.011*\"chapter\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 133567\n",
      "Fitting Time: 8089.266697883606\n",
      "Topic: 0 \n",
      "Words: 0.028*\"control\" + 0.020*\"version\" + 0.016*\"screen\" + 0.015*\"iphon\" + 0.013*\"button\" + 0.012*\"need\" + 0.012*\"touch\" + 0.011*\"breed\" + 0.011*\"ipad\" + 0.010*\"option\"\n",
      "Topic: 1 \n",
      "Words: 0.068*\"like\" + 0.032*\"thing\" + 0.030*\"dragon\" + 0.020*\"quest\" + 0.017*\"cloth\" + 0.015*\"abl\" + 0.014*\"stuff\" + 0.012*\"mayb\" + 0.012*\"need\" + 0.012*\"anim\"\n",
      "Topic: 2 \n",
      "Words: 0.091*\"game\" + 0.040*\"updat\" + 0.039*\"play\" + 0.025*\"time\" + 0.018*\"love\" + 0.018*\"crash\" + 0.017*\"problem\" + 0.014*\"work\" + 0.011*\"start\" + 0.010*\"go\"\n",
      "Topic: 3 \n",
      "Words: 0.123*\"game\" + 0.050*\"play\" + 0.018*\"great\" + 0.013*\"enjoy\" + 0.011*\"graphic\" + 0.011*\"best\" + 0.011*\"like\" + 0.011*\"time\" + 0.011*\"stori\" + 0.011*\"gameplay\"\n",
      "Topic: 4 \n",
      "Words: 0.026*\"game\" + 0.026*\"level\" + 0.020*\"player\" + 0.015*\"like\" + 0.012*\"battl\" + 0.010*\"hero\" + 0.009*\"fight\" + 0.009*\"weapon\" + 0.009*\"attack\" + 0.009*\"team\"\n",
      "Topic: 5 \n",
      "Words: 0.073*\"game\" + 0.041*\"money\" + 0.031*\"spend\" + 0.030*\"play\" + 0.025*\"time\" + 0.016*\"gem\" + 0.013*\"need\" + 0.013*\"free\" + 0.012*\"thing\" + 0.012*\"like\"\n",
      "Topic: 6 \n",
      "Words: 0.050*\"like\" + 0.023*\"peopl\" + 0.023*\"think\" + 0.021*\"love\" + 0.021*\"stori\" + 0.020*\"thing\" + 0.018*\"read\" + 0.017*\"want\" + 0.016*\"know\" + 0.012*\"chang\"\n",
      "Topic: 7 \n",
      "Words: 0.220*\"game\" + 0.121*\"love\" + 0.081*\"play\" + 0.042*\"awesom\" + 0.028*\"best\" + 0.028*\"friend\" + 0.028*\"like\" + 0.022*\"addict\" + 0.021*\"amaz\" + 0.016*\"great\"\n",
      "Topic: 8 \n",
      "Words: 0.159*\"charact\" + 0.025*\"custom\" + 0.012*\"simul\" + 0.011*\"choos\" + 0.010*\"skin\" + 0.009*\"ultim\" + 0.009*\"hunter\" + 0.008*\"option\" + 0.008*\"anim\" + 0.007*\"mate\"\n",
      "Topic: 9 \n",
      "Words: 0.160*\"game\" + 0.139*\"good\" + 0.060*\"great\" + 0.041*\"time\" + 0.040*\"like\" + 0.032*\"pretti\" + 0.019*\"nice\" + 0.018*\"littl\" + 0.018*\"better\" + 0.017*\"graphic\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sports Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe subcate reviews num of GP and Apple: 7083 122711\n",
      "number of reviews text: 129794\n",
      "number of neg: 30413\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 208\n",
      "number of pos: 85270\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 284\n"
     ]
    }
   ],
   "source": [
    "# analyse Arcade part\n",
    "df1 = dfSportsGP\n",
    "df2 = dfSportsAp\n",
    "gpNum = dfSportsGP.count()['text']\n",
    "ApNum = dfSportsAp.count()['text'] # text(reviews) number from apple\n",
    "print('targe subcate reviews num of GP and Apple:',gpNum,ApNum)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in df1.score.index:\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in df2.score.index:\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 30413\n",
      "Fitting Time: 712.5693264007568\n",
      "Topic: 0 \n",
      "Words: 0.086*\"game\" + 0.040*\"updat\" + 0.035*\"play\" + 0.035*\"crash\" + 0.026*\"time\" + 0.025*\"work\" + 0.020*\"load\" + 0.020*\"screen\" + 0.016*\"open\" + 0.013*\"iphon\"\n",
      "Topic: 1 \n",
      "Words: 0.057*\"game\" + 0.031*\"play\" + 0.027*\"lose\" + 0.025*\"shoot\" + 0.024*\"time\" + 0.023*\"ball\" + 0.019*\"coin\" + 0.016*\"oppon\" + 0.015*\"match\" + 0.014*\"player\"\n",
      "Topic: 2 \n",
      "Words: 0.075*\"game\" + 0.059*\"money\" + 0.031*\"spend\" + 0.019*\"purchas\" + 0.017*\"play\" + 0.014*\"free\" + 0.013*\"pay\" + 0.011*\"want\" + 0.011*\"develop\" + 0.009*\"buy\"\n",
      "Topic: 3 \n",
      "Words: 0.045*\"face\" + 0.040*\"work\" + 0.027*\"scan\" + 0.021*\"tri\" + 0.021*\"stupid\" + 0.016*\"mode\" + 0.015*\"beat\" + 0.014*\"charact\" + 0.014*\"fight\" + 0.014*\"hard\"\n",
      "Topic: 4 \n",
      "Words: 0.065*\"player\" + 0.050*\"game\" + 0.040*\"team\" + 0.027*\"play\" + 0.011*\"season\" + 0.011*\"like\" + 0.010*\"card\" + 0.010*\"pass\" + 0.009*\"lose\" + 0.009*\"time\"\n",
      "Topic: 5 \n",
      "Words: 0.065*\"level\" + 0.035*\"race\" + 0.029*\"upgrad\" + 0.021*\"game\" + 0.020*\"need\" + 0.017*\"car\" + 0.013*\"fish\" + 0.013*\"gold\" + 0.011*\"unlock\" + 0.011*\"money\"\n",
      "Topic: 6 \n",
      "Words: 0.151*\"game\" + 0.039*\"like\" + 0.029*\"play\" + 0.024*\"time\" + 0.020*\"wast\" + 0.019*\"worst\" + 0.019*\"star\" + 0.016*\"better\" + 0.015*\"good\" + 0.015*\"bore\"\n",
      "Topic: 7 \n",
      "Words: 0.070*\"ball\" + 0.029*\"game\" + 0.025*\"throw\" + 0.018*\"hit\" + 0.016*\"time\" + 0.016*\"pitch\" + 0.014*\"run\" + 0.013*\"basebal\" + 0.012*\"base\" + 0.012*\"go\"\n",
      "Topic: 8 \n",
      "Words: 0.060*\"control\" + 0.048*\"game\" + 0.026*\"graphic\" + 0.019*\"terribl\" + 0.014*\"button\" + 0.014*\"good\" + 0.014*\"horribl\" + 0.013*\"like\" + 0.011*\"gameplay\" + 0.011*\"great\"\n",
      "Topic: 9 \n",
      "Words: 0.113*\"game\" + 0.080*\"play\" + 0.037*\"time\" + 0.024*\"second\" + 0.022*\"watch\" + 0.016*\"annoy\" + 0.016*\"like\" + 0.014*\"add\" + 0.014*\"minut\" + 0.011*\"want\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 85270\n",
      "Fitting Time: 1754.373447418213\n",
      "Topic: 0 \n",
      "Words: 0.052*\"game\" + 0.027*\"worth\" + 0.019*\"review\" + 0.017*\"play\" + 0.013*\"cours\" + 0.012*\"enjoy\" + 0.012*\"free\" + 0.010*\"money\" + 0.009*\"develop\" + 0.009*\"definit\"\n",
      "Topic: 1 \n",
      "Words: 0.098*\"game\" + 0.056*\"level\" + 0.055*\"great\" + 0.052*\"time\" + 0.032*\"challeng\" + 0.025*\"hard\" + 0.022*\"like\" + 0.020*\"beat\" + 0.017*\"easi\" + 0.013*\"pass\"\n",
      "Topic: 2 \n",
      "Words: 0.153*\"good\" + 0.123*\"game\" + 0.043*\"graphic\" + 0.035*\"pretti\" + 0.035*\"control\" + 0.027*\"like\" + 0.024*\"great\" + 0.023*\"nice\" + 0.019*\"cool\" + 0.016*\"better\"\n",
      "Topic: 3 \n",
      "Words: 0.106*\"game\" + 0.067*\"best\" + 0.042*\"version\" + 0.032*\"iphon\" + 0.031*\"play\" + 0.024*\"real\" + 0.022*\"better\" + 0.020*\"like\" + 0.019*\"great\" + 0.019*\"golf\"\n",
      "Topic: 4 \n",
      "Words: 0.053*\"game\" + 0.027*\"time\" + 0.024*\"play\" + 0.022*\"ball\" + 0.013*\"lose\" + 0.013*\"problem\" + 0.011*\"go\" + 0.010*\"crash\" + 0.010*\"start\" + 0.009*\"get\"\n",
      "Topic: 5 \n",
      "Words: 0.206*\"game\" + 0.130*\"play\" + 0.081*\"love\" + 0.032*\"addict\" + 0.029*\"awesom\" + 0.023*\"like\" + 0.017*\"great\" + 0.016*\"time\" + 0.015*\"friend\" + 0.014*\"best\"\n",
      "Topic: 6 \n",
      "Words: 0.076*\"player\" + 0.063*\"game\" + 0.038*\"like\" + 0.036*\"team\" + 0.029*\"play\" + 0.011*\"season\" + 0.011*\"great\" + 0.011*\"better\" + 0.010*\"footbal\" + 0.010*\"soccer\"\n",
      "Topic: 7 \n",
      "Words: 0.038*\"game\" + 0.036*\"money\" + 0.033*\"race\" + 0.031*\"like\" + 0.027*\"coin\" + 0.027*\"upgrad\" + 0.024*\"car\" + 0.018*\"spend\" + 0.018*\"need\" + 0.016*\"thing\"\n",
      "Topic: 8 \n",
      "Words: 0.165*\"star\" + 0.039*\"give\" + 0.036*\"rat\" + 0.033*\"bowl\" + 0.026*\"connect\" + 0.023*\"rate\" + 0.020*\"reason\" + 0.017*\"robot\" + 0.017*\"fight\" + 0.013*\"awsom\"\n",
      "Topic: 9 \n",
      "Words: 0.060*\"game\" + 0.052*\"updat\" + 0.044*\"like\" + 0.036*\"love\" + 0.031*\"mode\" + 0.027*\"need\" + 0.024*\"add\" + 0.024*\"great\" + 0.019*\"thank\" + 0.018*\"thing\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
