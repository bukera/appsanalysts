{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zmz22\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zmz22\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # the stopwords \n",
    "def remain_english(line):\n",
    "    rule =re.compile(\"[^a-z^A-Z]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) # remain problems\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(str(text)) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "#             result.append(lemmatize_stemming(token))\n",
    "            result.append(remain_english(lemmatize_stemming((token))).lower()) # take out not english and return into verb, and lower it \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zmz22\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (14,15,16,19,22,24,26,27,28,31,34,37,38,39,40,43,46,48,50,51,52,55,58,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read file into pandas\n",
    "import pandas as pd\n",
    "fileGP = r'C:\\Users\\zmz22\\Downloads\\ToolsReview.csv'\n",
    "fileApple = r'C:\\Users\\zmz22\\Downloads\\apple-utilities-reviews.csv'\n",
    "\n",
    "df1 = pd.read_csv(fileGP)\n",
    "df2 = pd.read_csv(fileApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32609\n",
      "306673\n"
     ]
    }
   ],
   "source": [
    "print(df1.count()['text'])\n",
    "print(df2.count()['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews text: 339282\n",
      "number of neg: 83490\n",
      "number of inconsistant neg reviews text(actually a pos reviews): 607\n",
      "number of pos: 231696\n",
      "number of inconsistant pos reviews text(actually an neg reviews): 682\n"
     ]
    }
   ],
   "source": [
    "gpNum = df1.count()['text']\n",
    "ApNum = df2.count()['text'] # text(reviews) number from apple\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text_num = gpNum + ApNum\n",
    "# text_num = 5500\n",
    "documentNeg=[]\n",
    "documentPos=[]\n",
    "inconsistantNum1 = 0 # inconsistant reviews number in low rating reviews\n",
    "inconsistantNum2 = 0\n",
    "for i in range(gpNum):\n",
    "    if(df1.score[i]<3): # low rating reviews\n",
    "#         print(sid.polarity_scores(df1.text[i])['neg'])\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df1.text[i])             \n",
    "\n",
    "    if(df1.score[i]>3): # high rating reviews\n",
    "        if(sid.polarity_scores(str(df1.text[i]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df1.text[i]) \n",
    "            \n",
    "for j in range(ApNum):\n",
    "    if(df2.score[j]<3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['pos'] > 0.5): # 如果是这条评论的sensitive分析分数显示这条评论其实是负面的,threhold = 0.5\n",
    "            inconsistantNum1 += 1\n",
    "        else:\n",
    "            documentNeg.append(df2.text[j])             \n",
    "    if(df2.score[j]>3): # low rating reviews\n",
    "        if(sid.polarity_scores(str(df2.text[j]))['neg'] > 0.5): # if the neg score is high, not use this review,threhold = 0.5\n",
    "            inconsistantNum2 += 1\n",
    "        else:\n",
    "            documentPos.append(df2.text[j])      \n",
    "                        \n",
    "print('number of reviews text:',text_num)\n",
    "print('number of neg:',len(documentNeg))\n",
    "print('number of inconsistant neg reviews text(actually a pos reviews):',inconsistantNum1)\n",
    "print('number of pos:',len(documentPos))\n",
    "print('number of inconsistant pos reviews text(actually an neg reviews):',inconsistantNum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made doc_term_matrix\n",
      "object num 83490\n",
      "Fitting Time: 1556.308346748352\n",
      "Topic: 0 \n",
      "Words: 0.239*\"\" + 0.073*\"alarm\" + 0.066*\"video\" + 0.052*\"record\" + 0.050*\"play\" + 0.040*\"sound\" + 0.027*\"music\" + 0.019*\"clock\" + 0.017*\"wake\" + 0.014*\"song\"\n",
      "Topic: 1 \n",
      "Words: 0.029*\"call\" + 0.028*\"phone\" + 0.024*\"servic\" + 0.022*\"number\" + 0.021*\"month\" + 0.019*\"time\" + 0.017*\"block\" + 0.017*\"messag\" + 0.017*\"work\" + 0.014*\"issu\"\n",
      "Topic: 2 \n",
      "Words: 0.079*\"connect\" + 0.046*\"work\" + 0.037*\"devic\" + 0.029*\"camera\" + 0.022*\"wifi\" + 0.015*\"remot\" + 0.014*\"network\" + 0.013*\"view\" + 0.010*\"router\" + 0.010*\"tri\"\n",
      "Topic: 3 \n",
      "Words: 0.020*\"like\" + 0.016*\"page\" + 0.015*\"screen\" + 0.014*\"button\" + 0.014*\"keyboard\" + 0.013*\"search\" + 0.012*\"time\" + 0.011*\"look\" + 0.011*\"browser\" + 0.011*\"option\"\n",
      "Topic: 4 \n",
      "Words: 0.037*\"watch\" + 0.034*\"phone\" + 0.027*\"work\" + 0.025*\"turn\" + 0.014*\"like\" + 0.013*\"time\" + 0.013*\"lock\" + 0.012*\"light\" + 0.011*\"iphon\" + 0.010*\"notif\"\n",
      "Topic: 5 \n",
      "Words: 0.039*\"money\" + 0.034*\"free\" + 0.024*\"review\" + 0.024*\"wast\" + 0.023*\"star\" + 0.023*\"want\" + 0.022*\"pay\" + 0.021*\"like\" + 0.019*\"download\" + 0.016*\"purchas\"\n",
      "Topic: 6 \n",
      "Words: 0.018*\"data\" + 0.016*\"compani\" + 0.012*\"custom\" + 0.011*\"servic\" + 0.009*\"product\" + 0.009*\"year\" + 0.008*\"provid\" + 0.007*\"know\" + 0.007*\"plan\" + 0.007*\"poor\"\n",
      "Topic: 7 \n",
      "Words: 0.163*\"updat\" + 0.048*\"version\" + 0.041*\"iphon\" + 0.024*\"file\" + 0.020*\"ipad\" + 0.018*\"longer\" + 0.018*\"need\" + 0.018*\"latest\" + 0.014*\"fix\" + 0.014*\"upgrad\"\n",
      "Topic: 8 \n",
      "Words: 0.168*\"work\" + 0.068*\"time\" + 0.048*\"crash\" + 0.035*\"open\" + 0.033*\"download\" + 0.028*\"tri\" + 0.021*\"delet\" + 0.018*\"iphon\" + 0.017*\"wast\" + 0.015*\"keep\"\n",
      "Topic: 9 \n",
      "Words: 0.030*\"account\" + 0.023*\"password\" + 0.017*\"access\" + 0.015*\"card\" + 0.014*\"photo\" + 0.013*\"info\" + 0.013*\"say\" + 0.013*\"login\" + 0.013*\"inform\" + 0.011*\"enter\"\n"
     ]
    }
   ],
   "source": [
    "# negtive LDA  reviews analyse\n",
    "document = documentNeg\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "print('made doc_term_matrix')\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object num 231696\n",
      "Fitting Time: 3438.9082069396973\n",
      "Topic: 0 \n",
      "Words: 0.038*\"awesom\" + 0.034*\"love\" + 0.032*\"like\" + 0.029*\"cool\" + 0.028*\"keyboard\" + 0.022*\"light\" + 0.019*\"great\" + 0.018*\"text\" + 0.017*\"font\" + 0.014*\"color\"\n",
      "Topic: 1 \n",
      "Words: 0.027*\"like\" + 0.026*\"star\" + 0.021*\"review\" + 0.017*\"work\" + 0.016*\"nice\" + 0.014*\"browser\" + 0.013*\"open\" + 0.013*\"better\" + 0.012*\"search\" + 0.012*\"version\"\n",
      "Topic: 2 \n",
      "Words: 0.031*\"phone\" + 0.025*\"call\" + 0.024*\"number\" + 0.021*\"servic\" + 0.019*\"thank\" + 0.015*\"time\" + 0.012*\"year\" + 0.012*\"custom\" + 0.011*\"know\" + 0.011*\"block\"\n",
      "Topic: 3 \n",
      "Words: 0.391*\"\" + 0.054*\"ipod\" + 0.025*\"minecraft\" + 0.014*\"easiest\" + 0.010*\"guitar\" + 0.010*\"percentag\" + 0.009*\"touch\" + 0.007*\"homework\" + 0.007*\"gboard\" + 0.006*\"loop\"\n",
      "Topic: 4 \n",
      "Words: 0.119*\"love\" + 0.035*\"best\" + 0.034*\"alarm\" + 0.023*\"time\" + 0.021*\"sound\" + 0.017*\"clock\" + 0.016*\"great\" + 0.016*\"skin\" + 0.015*\"like\" + 0.014*\"wake\"\n",
      "Topic: 5 \n",
      "Words: 0.065*\"download\" + 0.032*\"video\" + 0.030*\"file\" + 0.027*\"record\" + 0.023*\"play\" + 0.020*\"photo\" + 0.020*\"amaz\" + 0.019*\"game\" + 0.017*\"great\" + 0.017*\"pictur\"\n",
      "Topic: 6 \n",
      "Words: 0.095*\"easi\" + 0.041*\"recommend\" + 0.035*\"simpl\" + 0.033*\"great\" + 0.025*\"work\" + 0.022*\"need\" + 0.021*\"calcul\" + 0.020*\"high\" + 0.019*\"app\" + 0.017*\"best\"\n",
      "Topic: 7 \n",
      "Words: 0.237*\"good\" + 0.083*\"like\" + 0.064*\"work\" + 0.033*\"pretti\" + 0.032*\"say\" + 0.020*\"peopl\" + 0.017*\"think\" + 0.016*\"know\" + 0.015*\"actual\" + 0.014*\"stuff\"\n",
      "Topic: 8 \n",
      "Words: 0.025*\"help\" + 0.019*\"use\" + 0.019*\"need\" + 0.018*\"time\" + 0.016*\"great\" + 0.014*\"batteri\" + 0.013*\"inform\" + 0.013*\"data\" + 0.012*\"accur\" + 0.012*\"level\"\n",
      "Topic: 9 \n",
      "Words: 0.075*\"work\" + 0.049*\"great\" + 0.026*\"updat\" + 0.023*\"iphon\" + 0.016*\"connect\" + 0.015*\"devic\" + 0.015*\"ipad\" + 0.013*\"issu\" + 0.012*\"support\" + 0.012*\"problem\"\n"
     ]
    }
   ],
   "source": [
    "# positive LDA reviews analyse\n",
    "document = documentPos\n",
    "doc_clean = [preprocess(doc) for doc in document]\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "print('object num',len(doc_term_matrix))\n",
    "start = time.time()\n",
    "lda_model = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=100, workers=4)\n",
    "# result = lda_model.print_topics(num_words=10)\n",
    "end = time.time()\n",
    "print ('Fitting Time:',end-start)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
